{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Development Indicators - Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>IndicatorName</th>\n",
       "      <th>IndicatorCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>ATG</td>\n",
       "      <td>Adolescent fertility rate (births per 1,000 wo...</td>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>1960</td>\n",
       "      <td>126.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>ATG</td>\n",
       "      <td>Age dependency ratio (% of working-age populat...</td>\n",
       "      <td>SP.POP.DPND</td>\n",
       "      <td>1960</td>\n",
       "      <td>88.237117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>ATG</td>\n",
       "      <td>Age dependency ratio, old (% of working-age po...</td>\n",
       "      <td>SP.POP.DPND.OL</td>\n",
       "      <td>1960</td>\n",
       "      <td>7.779958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>ATG</td>\n",
       "      <td>Age dependency ratio, young (% of working-age ...</td>\n",
       "      <td>SP.POP.DPND.YG</td>\n",
       "      <td>1960</td>\n",
       "      <td>80.457159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>ATG</td>\n",
       "      <td>Birth rate, crude (per 1,000 people)</td>\n",
       "      <td>SP.DYN.CBRT.IN</td>\n",
       "      <td>1960</td>\n",
       "      <td>32.920000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CountryName CountryCode  \\\n",
       "0  Antigua and Barbuda         ATG   \n",
       "1  Antigua and Barbuda         ATG   \n",
       "2  Antigua and Barbuda         ATG   \n",
       "3  Antigua and Barbuda         ATG   \n",
       "4  Antigua and Barbuda         ATG   \n",
       "\n",
       "                                       IndicatorName   IndicatorCode  Year  \\\n",
       "0  Adolescent fertility rate (births per 1,000 wo...     SP.ADO.TFRT  1960   \n",
       "1  Age dependency ratio (% of working-age populat...     SP.POP.DPND  1960   \n",
       "2  Age dependency ratio, old (% of working-age po...  SP.POP.DPND.OL  1960   \n",
       "3  Age dependency ratio, young (% of working-age ...  SP.POP.DPND.YG  1960   \n",
       "4               Birth rate, crude (per 1,000 people)  SP.DYN.CBRT.IN  1960   \n",
       "\n",
       "        Value  \n",
       "0  126.144000  \n",
       "1   88.237117  \n",
       "2    7.779958  \n",
       "3   80.457159  \n",
       "4   32.920000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "datos = pd.read_csv(\"suramerica.csv\").drop('Unnamed: 0', 1)\n",
    "paises = ['COL']\n",
    "\n",
    "preprocessing = 'imput'\n",
    "search = 'original'\n",
    "year_init = 2012\n",
    "year_range = 5\n",
    "look_back = 3\n",
    "years = range(year_init-year_range+1,year_init+1)[::-1]\n",
    "\n",
    "agricultura     = open(\"Indicadores/iagricultura.txt\").read().split(',')\n",
    "ambiente        = open(\"Indicadores/iambiente.txt\").read().split(',')\n",
    "ayuda           = open(\"Indicadores/iayuda.txt\").read().split(',')\n",
    "ciencia         = open(\"Indicadores/iciencia.txt\").read().split(',')\n",
    "clima           = open(\"Indicadores/iclima.txt\").read().split(',')\n",
    "comercio        = open(\"Indicadores/icomercio.txt\").read().split(',')\n",
    "deuda           = open(\"Indicadores/ideuda.txt\").read().split(',')\n",
    "economia        = open(\"Indicadores/ieconomia.txt\").read().split(',')\n",
    "educacion       = open(\"Indicadores/ieducacion.txt\").read().split(',')\n",
    "energia         = open(\"Indicadores/ienergia.txt\").read().split(',')\n",
    "finanzas        = open(\"Indicadores/ifinanzas.txt\").read().split(',')\n",
    "genero          = open(\"Indicadores/igenero.txt\").read().split(',')\n",
    "infraestructura = open(\"Indicadores/iinfraestructura.txt\").read().split(',')\n",
    "pobreza         = open(\"Indicadores/ipobreza.txt\").read().split(',')\n",
    "privado         = open(\"Indicadores/iprivado.txt\").read().split(',')\n",
    "publico         = open(\"Indicadores/ipublico.txt\").read().split(',')\n",
    "salud           = open(\"Indicadores/isalud.txt\").read().split(',')\n",
    "social          = open(\"Indicadores/isocial.txt\").read().split(',')\n",
    "trabajo         = open(\"Indicadores/itrabajo.txt\").read().split(',')\n",
    "urbano          = open(\"Indicadores/iurbano.txt\").read().split(',')\n",
    "\n",
    "\n",
    "conjunto_nombre = ['Agricultura','Ambiente','Ayuda','Ciencia','Clima','Comercio','Deuda','Economia','Educacion',\n",
    "                   'Energia','Finanzas','Genero','Infraestructura','Pobreza','Privado','Publico','Salud','Social',\n",
    "                   'Trabajo','Urbano']\n",
    "\n",
    "conjunto = [agricultura,ambiente,ayuda,ciencia,clima,comercio,deuda,economia,educacion,energia,finanzas,genero,\n",
    "            infraestructura,pobreza,privado,publico,salud,social,trabajo,urbano]\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def r2(y_true, y_predict):\n",
    "    from sklearn.metrics import r2_score\n",
    "    return r2_score(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tabla_base(indicadores):\n",
    "    tab = pd.DataFrame.pivot_table(datos, values='Value', index=['CountryCode', 'Year'], columns=['IndicatorCode']).loc[(paises,years),indicadores].sortlevel([\"CountryCode\",\"Year\"], ascending=[True,False])\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tabla_2_base(indicadores,look_back):\n",
    "    temp_table = []\n",
    "    for i in range(look_back):      \n",
    "        temp_years = range(year_init-year_range-i+1,year_init-i+1)[::-1]\n",
    "        temp_table.append(pd.DataFrame.pivot_table(datos, values='Value', index=['CountryCode', 'Year'], columns=['IndicatorCode']).loc[(paises,temp_years),indicadores].sortlevel([\"CountryCode\",\"Year\"], ascending=[True,False]))\n",
    "    return pd.DataFrame(np.column_stack(temp_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimator_Universal(estimador, X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.svm import SVR\n",
    "    \n",
    "    if(search=='original'):\n",
    "        if(estimador=='DTR'):\n",
    "            estimator = DecisionTreeRegressor()\n",
    "        if(estimador=='RFR'):\n",
    "            estimator = RandomForestRegressor(n_jobs=-1)\n",
    "        if(estimador=='SVR'):\n",
    "            estimator = SVR()\n",
    "    else:\n",
    "        best_params = SearchCV_Universal(estimador, search, X_train, y_train)       \n",
    "\n",
    "        if(estimador=='DTR'):\n",
    "            estimator = DecisionTreeRegressor().set_params(**best_params)\n",
    "        if(estimador=='RFR'):\n",
    "            estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "        if(estimador=='SVR'):\n",
    "            estimator = SVR().set_params(**best_params)\n",
    "        \n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "        \n",
    "    return r2(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Preprocess(tab1,tab2,y_indicator):\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    #Eliminamos las columnas de NaN descartando Indicadores que no tienen regristros para ningún pais y año deseados\n",
    "    tab1 = tab1.dropna(how='all',axis=1)\n",
    "    tab2 = tab2.dropna(how='all',axis=1)\n",
    "\n",
    "    if(preprocessing=='zeros'):\n",
    "        #Imputamos los NaN por Zero\n",
    "        tab1 = tab1.fillna(0)      \n",
    "\n",
    "    if(preprocessing=='imput'):\n",
    "        #Imputamos los NaN por la media de cada Indicador respectivamente      \n",
    "        impute=Imputer(missing_values=\"NaN\",strategy='mean',axis=0)\n",
    "        impute.fit(tab1)\n",
    "        tab1 = pd.DataFrame(impute.transform(tab1))\n",
    "\n",
    "    #Fusionamos la tabla_1 y el indicador y de la tabla_2\n",
    "    tab_fusion = pd.DataFrame(np.column_stack((np.array(tab1)[:,:],np.array(tab2)[:,y_indicator])))\n",
    "\n",
    "    #Eliminamos las filas Si el valor a predecir es NaN\n",
    "    tab_fusion = tab_fusion.dropna(subset=[tab_fusion.iloc[:,-1].name])\n",
    "\n",
    "    # Asignamos X e y, eliminando los indicadores que se correlacionen más con el indicador a predecir (coeficiente > 0.7)\n",
    "    tab_fusion_corr = tab_fusion.corr()\n",
    "    X = tab_fusion.drop(tab_fusion_corr[tab_fusion_corr.iloc[:,-1] > 0.7].index, axis=1)\n",
    "    y = tab_fusion.iloc[:,-1]\n",
    "\n",
    "    # Normalizamos los datos\n",
    "    sc = StandardScaler()\n",
    "    tab_fusion_norm = sc.fit_transform(np.column_stack([X,y]))\n",
    "    X = tab_fusion_norm[:,:-1]\n",
    "    y = tab_fusion_norm[:,-1]\n",
    "\n",
    "    # Separamos Train y Test respectivamente para X e y\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_Splitter_Optimus(tab1,tab2): \n",
    "    R2_global = list()\n",
    "    for i in range(0,np.shape(tab2.dropna(how='all',axis=1))[1]):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = Preprocess(tab1, tab2, i)\n",
    "\n",
    "        result = estimator_Universal('DTR', X_train, X_test, y_train, y_test)\n",
    "\n",
    "        if(result < 0.9): \n",
    "            temp = estimator_Universal('SVR', X_train, X_test, y_train, y_test)\n",
    "            if(temp < 0.9): \n",
    "                temp2 = estimator_Universal('RFR', X_train, X_test, y_train, y_test)\n",
    "                if (temp2 > temp): \n",
    "                    result = temp2\n",
    "            if(temp > result): \n",
    "                result = temp\n",
    "        print i , result\n",
    "        R2_global.append(result)\n",
    "    return R2_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SearchCV_Universal(estimador, search, X_train, y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.svm import SVR\n",
    "        \n",
    "    if(estimador=='DTR'):\n",
    "        estimator  = DecisionTreeRegressor()\n",
    "        param_grid = {  'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "                        'splitter': ['best', 'random']\n",
    "                     }\n",
    "        \n",
    "    if(estimador=='RFR'):\n",
    "        estimator  = RandomForestRegressor()       \n",
    "        param_grid = { \n",
    "                        \"n_estimators\"      : [10,20,30,40],\n",
    "                        \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "                        \"min_samples_split\" : [2,4,8],\n",
    "                        \"bootstrap\": [True, False],\n",
    "                     }\n",
    "    if(estimador=='SVR'):\n",
    "        estimator  = SVR()\n",
    "        param_grid ={\n",
    "                        'gamma'  : ['auto', 1e-3, 1e-4],\n",
    "                        'C'      : [1, 10, 100, 1000],            \n",
    "                    }\n",
    "\n",
    "    if (search=='random'):\n",
    "        grid = RandomizedSearchCV(estimator, param_grid, n_jobs=-1, cv=ShuffleSplit(test_size=0.2))\n",
    "    if (search=='grid'):\n",
    "        grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=ShuffleSplit(test_size=0.2))\n",
    "        \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filtro(indicadores_1,indicadores_2):\n",
    "    if(indicadores_1!=indicadores_2):\n",
    "        df = pd.DataFrame(indicadores_2)\n",
    "        indicadores_2 = np.array(df.loc[~df.ix[:,0].isin(indicadores_1)]).flatten()\n",
    "    return indicadores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterador_global(indicadores_1,indicadores_2,look_back): \n",
    "    \n",
    "    tab1 = tabla_2_base(indicadores_1,look_back)\n",
    "    tab2 = tabla_base(filtro(indicadores_1,indicadores_2))\n",
    "    \n",
    "    return iter_Splitter_Optimus(tab1,tab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.9</td>\n",
       "      <td>49.806023</td>\n",
       "      <td>0.944369</td>\n",
       "      <td>38.411537</td>\n",
       "      <td>426176.0</td>\n",
       "      <td>66.260984</td>\n",
       "      <td>42975.0</td>\n",
       "      <td>82.469443</td>\n",
       "      <td>20228.05</td>\n",
       "      <td>2.422891</td>\n",
       "      <td>...</td>\n",
       "      <td>1165592.23</td>\n",
       "      <td>116.53</td>\n",
       "      <td>1.689950</td>\n",
       "      <td>11437562.0</td>\n",
       "      <td>24.397</td>\n",
       "      <td>-0.131803</td>\n",
       "      <td>19.5</td>\n",
       "      <td>46.8</td>\n",
       "      <td>1141748.0</td>\n",
       "      <td>8.570292e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.5</td>\n",
       "      <td>48.960221</td>\n",
       "      <td>0.944369</td>\n",
       "      <td>37.603425</td>\n",
       "      <td>417210.0</td>\n",
       "      <td>66.260984</td>\n",
       "      <td>42975.0</td>\n",
       "      <td>82.469443</td>\n",
       "      <td>20228.05</td>\n",
       "      <td>2.499631</td>\n",
       "      <td>...</td>\n",
       "      <td>1136557.50</td>\n",
       "      <td>110.30</td>\n",
       "      <td>1.643082</td>\n",
       "      <td>11452647.0</td>\n",
       "      <td>24.679</td>\n",
       "      <td>-0.090314</td>\n",
       "      <td>19.2</td>\n",
       "      <td>46.1</td>\n",
       "      <td>1141750.0</td>\n",
       "      <td>5.124973e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.1</td>\n",
       "      <td>48.114419</td>\n",
       "      <td>0.944369</td>\n",
       "      <td>38.308247</td>\n",
       "      <td>425030.0</td>\n",
       "      <td>65.659383</td>\n",
       "      <td>43791.0</td>\n",
       "      <td>80.011853</td>\n",
       "      <td>20116.50</td>\n",
       "      <td>3.505426</td>\n",
       "      <td>...</td>\n",
       "      <td>1039816.70</td>\n",
       "      <td>106.20</td>\n",
       "      <td>1.433078</td>\n",
       "      <td>11462995.0</td>\n",
       "      <td>24.964</td>\n",
       "      <td>-0.044211</td>\n",
       "      <td>21.6</td>\n",
       "      <td>49.7</td>\n",
       "      <td>1141750.0</td>\n",
       "      <td>6.821874e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.5</td>\n",
       "      <td>48.960221</td>\n",
       "      <td>0.944369</td>\n",
       "      <td>38.341595</td>\n",
       "      <td>425400.0</td>\n",
       "      <td>66.260984</td>\n",
       "      <td>42975.0</td>\n",
       "      <td>82.469443</td>\n",
       "      <td>20228.05</td>\n",
       "      <td>3.602386</td>\n",
       "      <td>...</td>\n",
       "      <td>1160333.00</td>\n",
       "      <td>106.34</td>\n",
       "      <td>1.423164</td>\n",
       "      <td>11468064.0</td>\n",
       "      <td>25.251</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>20.1</td>\n",
       "      <td>53.7</td>\n",
       "      <td>1141750.0</td>\n",
       "      <td>9.973594e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.5</td>\n",
       "      <td>48.960221</td>\n",
       "      <td>0.944369</td>\n",
       "      <td>38.408292</td>\n",
       "      <td>426140.0</td>\n",
       "      <td>66.862586</td>\n",
       "      <td>42159.0</td>\n",
       "      <td>84.927034</td>\n",
       "      <td>20339.60</td>\n",
       "      <td>3.524266</td>\n",
       "      <td>...</td>\n",
       "      <td>1182990.00</td>\n",
       "      <td>116.31</td>\n",
       "      <td>1.470032</td>\n",
       "      <td>11467884.0</td>\n",
       "      <td>25.540</td>\n",
       "      <td>0.047701</td>\n",
       "      <td>20.1</td>\n",
       "      <td>56.6</td>\n",
       "      <td>1141750.0</td>\n",
       "      <td>6.014233e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0          1         2          3         4          5        6   \\\n",
       "0  87.9  49.806023  0.944369  38.411537  426176.0  66.260984  42975.0   \n",
       "1  89.5  48.960221  0.944369  37.603425  417210.0  66.260984  42975.0   \n",
       "2  91.1  48.114419  0.944369  38.308247  425030.0  65.659383  43791.0   \n",
       "3  89.5  48.960221  0.944369  38.341595  425400.0  66.260984  42975.0   \n",
       "4  89.5  48.960221  0.944369  38.408292  426140.0  66.862586  42159.0   \n",
       "\n",
       "          7         8         9       ...               33      34        35  \\\n",
       "0  82.469443  20228.05  2.422891      ...       1165592.23  116.53  1.689950   \n",
       "1  82.469443  20228.05  2.499631      ...       1136557.50  110.30  1.643082   \n",
       "2  80.011853  20116.50  3.505426      ...       1039816.70  106.20  1.433078   \n",
       "3  82.469443  20228.05  3.602386      ...       1160333.00  106.34  1.423164   \n",
       "4  84.927034  20339.60  3.524266      ...       1182990.00  116.31  1.470032   \n",
       "\n",
       "           36      37        38    39    40         41            42  \n",
       "0  11437562.0  24.397 -0.131803  19.5  46.8  1141748.0  8.570292e+09  \n",
       "1  11452647.0  24.679 -0.090314  19.2  46.1  1141750.0  5.124973e+09  \n",
       "2  11462995.0  24.964 -0.044211  21.6  49.7  1141750.0  6.821874e+09  \n",
       "3  11468064.0  25.251  0.001570  20.1  53.7  1141750.0  9.973594e+09  \n",
       "4  11467884.0  25.540  0.047701  20.1  56.6  1141750.0  6.014233e+09  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_indicator = 3\n",
    "tab1 = tabla_2_base(conjunto[0],1)\n",
    "tab2 = tabla_base(filtro(conjunto[0],conjunto[1]))\n",
    "\n",
    "#Eliminamos las columnas de NaN descartando Indicadores que no tienen regristros para ningún pais y año deseados\n",
    "tab1 = tab1.dropna(how='all',axis=1)\n",
    "tab2 = tab2.dropna(how='all',axis=1)\n",
    "\n",
    "if(preprocessing=='zeros'):\n",
    "    #Imputamos los NaN por Zero\n",
    "    tab1 = tab1.fillna(0)      \n",
    "\n",
    "if(preprocessing=='imput'):\n",
    "    #Imputamos los NaN por la media de cada Indicador respectivamente      \n",
    "    impute=Imputer(missing_values=\"NaN\",strategy='mean',axis=0)\n",
    "    impute.fit(tab1)\n",
    "    tab1 = pd.DataFrame(impute.transform(tab1))\n",
    "\n",
    "#Fusionamos la tabla_1 y el indicador y de la tabla_2\n",
    "tab_fusion = pd.DataFrame(np.column_stack((np.array(tab1)[:,:],np.array(tab2)[:,y_indicator])))\n",
    "\n",
    "tab_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def porcent_result_reg(df,indicadores_1,indicadores_2):\n",
    "    df = pd.DataFrame(df)\n",
    "    df[df < 0] = 0.0\n",
    "    porcent = df.mean().values[0]\n",
    "    result = np.array(df.values)   \n",
    "    reg = len(filtro(indicadores_1,indicadores_2))\n",
    "    return porcent,result,reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteramos todos los Conjuntos de Indicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 43)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1a8cf0cf281c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mstart_time2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mporcent\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mporcent_result_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterador_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconjunto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconjunto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconjunto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconjunto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mresultado_global\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconjunto_nombre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconjunto_nombre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mporcent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultado_global\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Base\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Target\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Look Back\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Reg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'colombia_original_log.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-6e4074306b90>\u001b[0m in \u001b[0;36miterador_global\u001b[0;34m(indicadores_1, indicadores_2, look_back)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtab2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabla_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicadores_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindicadores_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter_Splitter_Optimus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtab2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-ffd33080c0fa>\u001b[0m in \u001b[0;36miter_Splitter_Optimus\u001b[0;34m(tab1, tab2)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtab2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_Universal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DTR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-d553e6af2f8f>\u001b[0m in \u001b[0;36mestimator_Universal\u001b[0;34m(estimador, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/familia-plazas/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/familia-plazas/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/familia-plazas/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    414\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 416\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 43)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "resultado_global = []\n",
    "\n",
    "for i in range(len(conjunto)):\n",
    "    for j in range(len(conjunto)):\n",
    "        for k in range(1,look_back+1):\n",
    "            start_time2 = time.time()\n",
    "            porcent , results, reg = porcent_result_reg(iterador_global(conjunto[i],conjunto[j],k),conjunto[i],conjunto[j])\n",
    "            resultado_global.append([conjunto_nombre[i],conjunto_nombre[j],k,reg,porcent,\"%s\" % (time.time() - start_time2),results])\n",
    "            pd.DataFrame(resultado_global, columns=[\"Base\",\"Target\",\"Look Back\",\"Reg\",\"%\",\"Time\",\"Results\"]).to_csv('colombia_original_log.csv')\n",
    "\n",
    "\n",
    "df_global = pd.DataFrame(resultado_global, columns=[\"Base\",\"Target\",\"Look Back\",\"Reg\",\"%\",\"Time\",\"Results\"])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,1):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,20):\n",
    "    print j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
